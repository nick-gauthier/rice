---
title: "Rice Ecological Niche Modeling"
author: "Nick Gauthier"
date: "`r Sys.Date()`"
format: html
editor: visual
knitr: 
  opts_chunk:
    echo: FALSE
---

```{r setup, message = FALSE, warning = FALSE}
# analysis packages
library(stars) # spatio-temporal raster processing
library(tidyverse) # data manipulation and plotting
library(tidymodels) # machine learning
library(geodata) # geographic data
library(here) # cross-platform directory structures
library(readxl) # read excel spreadsheets
library(exactextractr)
# library(dismo) # generating background points for niche model, not loaded but should be installed
#library(themis)
library(colino)

# parallel processing
library(doMC)
available_cores <- parallel::detectCores(logical = TRUE)

# visualization packages
library(rnaturalearth) # country boundaries
library(vip) # variable importance plots

# define the study area
bbox <- st_bbox(c(xmin = 60, xmax = 150, ymin = -20, ymax = 50), crs = 4326)
# create a 10' reference raster
ref <- st_as_stars(bbox, dx = 0.166667)
#sf_use_s2(FALSE)

# get country boundaries shapefile for plotting
countries <- ne_countries(returnclass = "sf", scale = 'large') %>%
  st_crop(bbox)
coasts <- ne_coastline(returnclass = 'sf') %>%
  st_crop(bbox)

theme_set(theme_bw())
```

# Modeling the climatic niche of rice

## Rice occurrence data

Read in the GBIF/CHV occurrence data for rice's wild progenitor (Oryza rufipogon G.) from [here](https://www.sciencedirect.com/science/article/pii/S1574954122002631). Also load occurrence records of domestic rice from the same source, as well as occurrences of botanical remains thought to be *O. sativa japonica* from archaeological sites.

```{r, fig.width=4, fig.height = 4, warning=FALSE}
occ <- here('data', 'Datasets of occurrence records of rice and its wild progenitor.xlsx')
progenitor <- read_excel(occ, skip = 6715) %>%
  select(-x, -`the wild progenitor`) %>%
  st_as_sf(coords = 2:1, crs = 4326) %>%
  st_crop(bbox) %>%
  mutate(rice = 'present')

domestic <- read_excel(occ, n_max = 6714) %>%
  remove_missing() %>%
  select(-x, -Rice) %>%
  st_as_sf(coords = 2:1, crs = 4326) %>%
    st_crop(bbox) %>%
  mutate(rice = 'present')

arch <- here('data', 'Archaeological Rice Dataset.xlsx') %>%
  read_excel() %>%
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = 4326) %>%
  rename(age = `Est._Date_Median_BC`) %>%
  arrange(-age)

ggplot() +
  geom_sf(data = coasts) +
  geom_sf(data = st_crop(domestic, bbox), alpha = .5) +
  geom_sf(data = st_crop(progenitor, bbox), color = 'green', alpha = .5) +
    labs(title = "Rice occurence data", subtitle = "O. sativa (modern, black), O. rufipogon (modern, green), O. sativa japonica (archaeological, red)", caption = 'source: GBIF, CHV, Rice Archaeological Database') +
  geom_sf(data = arch, color = 'red', alpha = .5) +
  theme_minimal()
```

```{r}
oryza <- read_tsv('0266607-220831081235567.csv') %>%
  st_as_sf(coords = c('decimalLongitude', 'decimalLatitude'), crs = 4326) %>%
  st_crop(bbox)

ggplot() +
  geom_sf(data = coasts) +
  geom_sf(data = oryza, alpha = .5) +
  theme_minimal()
```

```{r}
dgg <- read_sf('../future-anthromes/data/data-raw/dgg_land.gpkg') %>%
  st_crop(bbox) 

plot(dgg['L1_ID'], lwd = 0.1)
```

```{r, cache = TRUE}
occ_dgg <- dgg %>%
   mutate(oryza =  lengths(st_intersects(dgg, oryza)) > 0,
          rufip = lengths(st_intersects(dgg, progenitor)) > 0,
          sativa = lengths(st_intersects(dgg, domestic)) > 0,
          arch = lengths(st_intersects(dgg, arch)) > 0,
          geom = st_centroid(geom))


ggplot() +
    geom_sf(data = coasts) +
  geom_sf(data = filter(occ_dgg, oryza == TRUE), size = .1) +
    geom_sf(data = filter(occ_dgg, rufip == TRUE), size = .1, color = 'green') +
      geom_sf(data = filter(occ_dgg, sativa == TRUE), size = .1, color = 'blue') +
    geom_sf(data = filter(occ_dgg, arch == TRUE), size = .1, color = 'red') +
  theme_minimal()
```

```{r}
occ_dgg %>%
  summary
```

## Climate data

Load the CHELSA V2 bioclimate layers. They come at a native 1km resolution, which is a bit too optimistic. We'll extract them to a larger equal-area grid system.

```{r cache = TRUE}
chelsa_files <- list.files('../../CHELSA_V2_bio_clim', 
                           full.names = TRUE)[c(2:20)]#, 60:70)]#70)]

chelsa_names <- chelsa_files %>% 
  str_split('_') %>% 
  map_chr(~.x[5])

bbox <- terra::ext(60, 150, -20, 50)

chelsa <- terra::rast(chelsa_files) %>%
  terra::crop(bbox) %>%
  exact_extract(dgg, 'mean') %>% 
  rename_with(~str_remove(.x, 'mean.'))

#chelsa <- chelsa_files %>%
#  read_stars(shorten = FALSE) %>%
#  st_crop(bbox) %>%
#  setNames(chelsa_names)
#chelsa_rast <- chelsa_files %>%
#    terra::rast() %>%
#    setNames(chelsa_names)
```

```{r eval = FALSE}
saveRDS(chelsa_dgg, 'data/data-derived/chelsa_dgg.RDS')
chelsa_dgg <- readRDS('data/data-derived/chelsa_dgg.RDS')
```

## Ecological niche modeling

Sample background points from the CHELSA data for the ENM.

```{r}
dat <- occ_dgg %>%
  bind_cols(chelsa_dgg) %>%
  st_drop_geometry()
```

```{r eval = FALSE}
saveRDS(dat, 'data/data-derived/dat.RDS')
dat <- readRDS('data/data-derived/dat.RDS')
```

we shifts w/archy distribution in bio9, mean temp of driest quarter (arch is colder in the driest) and bio 11, mean temp of coldest quarter. bio11 is one of the more important variables for rufip, and interestingly it clearly separates that from arch. cold. Bio3 is also notably lower for arch than others and clearly separates. bio3 is isothermality (bio2/bio7), and this shift likley comes from bio7, which is temp annual range based on 5 and 6. a bit is coming from 5 mut mostly from 6

```{r, fig.width=8, fig.height = 2}
train %>%
  select(bio1:bio9, oryza, rufip, sativa, arch) %>%
  pivot_longer(oryza:arch, names_to = 'variety', values_to = 'present') %>%
  filter(present == TRUE) %>%
  pivot_longer(bio1:bio9, names_to = 'bio') %>%
  ggplot(aes(value)) +
  geom_histogram()+
  facet_grid(variety~bio, scales = 'free')
```

So the question here is whether to include background cells where there are occurrence cells. -- this kinda violates the point of the "background", but it does feel weird to copy things

```{r}
#dat2 <- dat %>%
#  mutate(rufip = FALSE) %>%
#  bind_rows(filter(dat, rufip == TRUE))
  
set.seed(12345)
# is stratification actually happening here? the diff is more than 10%
splits <- initial_split(dat, strata = rufip)
train <- training(splits)
folds <- vfold_cv(train, v = 5, repeats = 2, strata = rufip)

```

establish some metrics

```{r}
c_metrics <- metric_set(f_meas, roc_auc, pr_auc, j_index, sens, spec, kap, precision)
```

Get the class imbalances.

```{r}
classes <- table(train$rufip)
occ_ratio <- classes[2]/classes[1]
occ_ratio
```

```{r}
train %>%
  arrange(rufip) %>%
  ggplot(aes(bio1, bio12, color = rufip)) +
  geom_point()
```

### First Tuning

#### J

J index (sens + spec -1, 1) means no false positives and no false negatives. downsampling within and without do well . down10 is consistently worse, and the worse is normal without any downsampling at all. so the downsampling is increasing our J index, because without it we were probably getting degenerate models that just always predicted absences or something.

```{r}
rank_results(tuning, 'j_index') %>%
  filter(.metric == 'j_index') %>%
  ggplot(aes(rank, mean)) +
  geom_point() +
  labs(y = 'j_index')
```

#### Kappa

Kappa is like balanced accuracy, down10 normal by far. kappa is dependent on the prevalence of the species. so it really likes down10 for some reason, then are the normal recipes withot , then with the downsaling in the rf. and the absolute worst at zero are the double downsamples. so the takeaway from this

```{r}
rank_results(tuning, 'kap') %>%
  filter(.metric == 'kap') %>%
     ggplot(aes(rank, mean)) +
  geom_point() +
  labs(y = 'kap')
```

#### AUC-PR

[This paper](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13140) says area under the precision recall curve (AUC-PR) and precision are good for sdm on presence-background data. Precision is the probability that a predicted location will have an observed species in it. Here the model likes down1_ds. Then there is a clear second tier, led by norm_norm, then norm_ds, followed by down10 and down 1. far and away the wrose is down10_ds. Interesting, here the big difference was between downsampilng everything and nothing basically, and both turned out ok. In general this is going to be influenced by the prevalence so in

```{r}
rank_results(tuning, 'pr_auc') %>%
  filter(.metric == 'pr_auc') %>%
    ggplot(aes(rank, mean)) +
  geom_point() +
  labs(y = 'pr_auc')
```

But AUC-ROC is still good for *potential* ranges.

> However, both AUC-PR and precision penalize false positives, and so may be less appropriate for modelling species' potential ranges. This is because locations may be correctly identified as having high potential suitability, despite being currently unoccupied. AUC-ROC has similarly been recognized to be most useful for modelling realized rather than potential ranges (Jiménez-Valverde, [**2012**](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13140#mee313140-bib-0027)).

#### AUC-ROC

In that case, roc_auc performs well for everything except **down1_ds**. These are the same that perform well for the AUC-PR. But norm hell_ds is the best. That suggests that the even downsampling makes the extrapolation model work better. but the regular down1 ones are fine. so that suggests downsampling on both sides of the random forest is whats really bad. Everything else is great, but notabley the hellinger_ds is top and the norm_hellinger without downsampling is "worst." This is one of the few cases where hellinger makes a difference, but its prety small

This metric selects basically anything except the double downsample. which is reasonable.

```{r}
rank_results(tuning, 'roc_auc') %>%
  filter(.metric == 'roc_auc') %>%
  ggplot(aes(rank, mean)) +
  geom_point() +
  labs(y = 'roc_auc')
```

```{r}
autoplot(tuning)
```

### Takeaways

I'm noticing hellinger is usually slightly better than the normal alternative, but overall everything else matters more. Well, is hellinger ever any worse? Once.

So after hellinger how we think about downsampling within the folds?

don't do in folds and in bootstraps -- that seems to do poorly for everything but precision. I guess that may be undersampling the potential background points?

### Second tuning

Now we've decided to do the within RF subsampling rather than outer rf subsampling. [This paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201904#sec002) suggests even subsampling is desirable, although stratified subsampling also works. But in general you can use the oob error estimates and they'll be fairly unbaised. but you have to subsample 0.632\*lowclassprob instead of bootstrap for reasons they cite.

> An approach called "balanced random forest" \[[34](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201904#pone.0201904.ref034)\] tackles this imbalance by drawing the same numbers of observations with replacement from each class for each tree yielding trees that do not preferentially predict a specific class. 
>
> For unbalanced data, both when sampling the same numbers of observations (balanced RF) and when using sampling fractions that are proportional to the class sizes, the class-specific OOB errors are (almost) unbiased with respect to the corresponding class-specific test errors. Sampling the same numbers of observations from each class yields a RF that has the same prediction performance independent of the class an observation comes from. For observations from the smaller class prediction performance is considerably higher than that obtained when using sampling fractions that are proportional to the class sizes. Nevertheless, for observations from the larger class, sampling fractions that are proportional to the class sizes performs slightly better than sampling the same numbers from each class. *In unbalanced settings, in which there is a strong interest in predicting observations from the smaller classes well, sampling the same number of observations from each class might therefore be the method of choice.*
>
> Two main conclusions are drawn from these studies: (i) When choosing the *mtry* value using the OOB error, stratified subsampling can yield downwardly biased error rate estimates if the stratified OOB error that is smallest across all *mtry* values is used as an estimate of the generalization error; (ii) This bias can be greatly reduced by constructing a new RF using the *mtry* value that was chosen based on the stratified OOB error, and reporting the stratified OOB error of the new RF as an estimate of the generalization error. The latter point can be justified by the very small downward bias from procedure (2) that is observed for stratified subsampling in the analysis, even so the simulation setting with the highest variability of the OOB error estimates was used. **Nevertheless, the gold standard procedure is using stratified CV for error estimation, choosing an optimal *mtry* value using the stratified OOB error in each iteration of the stratified CV.**

```{r}
rec <- train %>%
  recipe() %>%
  update_role(starts_with('bio'), new_role = 'predictor') %>%
  update_role(rufip, new_role = 'outcome') %>%
  update_role(ANL12_ID, new_role = 'id') %>%
  step_bin2factor(all_outcomes()) %>%
  step_rm(!has_role(c('predictor', 'outcome', 'id')))
 
rf_mod <- rand_forest(mode = 'classification',
                         trees = 1000,
                         mtry = tune(),
                         min_n = tune()) %>%
  set_engine('ranger',
             replace = FALSE,
             sample.fraction = c(0.632 * occ_ratio, 
                                 0.632 * occ_ratio))

wflw <- workflow(rec, rf_mod)

registerDoMC(cores = available_cores)
res <- tune_bayes(wflw, folds, metrics = c_metrics)
registerDoSEQ()
```

```{r}
autoplot(res)
```

This selects a model with mtry = 6 and min_n = 4

```{r}
best_rf <- select_best(res)
best_rf
saveRDS(best_rf, here('data/data-derived/best_rf.rds'))
```

### Variable importance

Now the winning model will be retrained on the training data and we'll do some variable importance exploration. Because we selected a low mtry we're getting a more informative view.

dfa

The VIP gives the following variables:

1.  BIO6 = Min Temperature of Coldest Month
2.  BIO11 = Mean Temperature of Coldest Quarter
3.  BIO15 = Precipitation Seasonality (Coefficient of Variation)
4.  BIO4 = Temperature Seasonality (standard deviation ×100)
5.  BIO7 = Temperature Annual Range (BIO5-BIO6)
6.  BIO18 = Precipitation of Warmest Quarter
7.  BIO1 = Annual Mean Temperature\

6 and 11 were shown to dominate the first pc in \[this paper\](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12244)

```{r}
final_mod <- rand_forest(mode = 'classification',
                         trees = 1000,
                         mtry = 6,
                         min_n = 4) %>%
  set_engine('ranger',
             importance = 'permutation',
             replace = FALSE,
             sample.fraction = c(0.632 * occ_ratio, 
                                 0.632 * occ_ratio))

final_fit <- last_fit(final_mod, rec, splits, metrics = c_metrics)

extract_fit_engine(final_fit) %>%
  vip(geom = "point", num_features = 19)
```

```{r}
prep(rec) %>% juice %>%
  select(-ANL12_ID) %>%
  recipe(rufip ~ .) %>%
  step_corr(all_numeric_predictors()) %>%
  prep %>%
  juice
```

PC1 is temperaturel bio 7 is temp annual range (5-6), 6 is min temp coldest month, 11 mean temp coldest quarter, 4 is seasonality. so basically these are cold tmeps annaul temps and seasonality indicators.

PC2 is max temp warmerst month and quarter positive and negative are basically summer rainfall indicators.

PC3 is precip seasonality and wenss indicators

PC4 unclear

```{r}
# install.packages("devtools")
#devtools::install_github("tidymodels/learntidymodels")
prep(rec) %>% 
  juice %>%
  select(-ANL12_ID) %>%
  recipe(rufip ~ .) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors()) %>%
  prep() %>% 
  learntidymodels::plot_top_loadings(component_number <= 5, n = 10) 
```

```{r}
remotes::install_github('stevenpawley/colino')
install.packages("praznik")
install.packages("FSelectorRcpp")
library('colino')

rec_filter_mrmr <-
 rec %>%
 step_select_mrmr(
   all_predictors(),
   outcome = "rufip",
   threshold = 0.5
 )

tut2 <- prep(rec_filter_mrmr)

tut2 %>% tidy(3)

tut2 %>% juice()

rec_filter_info <-
 rec %>%
 step_select_infgain(
   all_predictors(),
   outcome = "rufip",
  threshold = 0.75,
   nthreads = 0
   #top_p = 5
 )

tut3 <- prep(rec_filter_info)

tut3 %>% tidy(3)

tut3 %>% juice()

```

The permutation variable selection selects 11, 15, 4, 6, 7

The mrmrm seleects 11, 15, 18, 19, 8

BIO11 = Mean Temperature of Coldest Quarter

BIO15 = Precipitation Seasonality (Coefficient of Variation)

BIO18 = Precipitation of Warmest Quarter

> BIO19 = Precipitation of Coldest Quarter\
> BIO8 = Mean Temperature of Wettest Quarter

with 90% threshold we get 11 and 18, so cold temps and warm season precip\
\
infogain gives top 5 as bio1, bio4, bio6, bio7, bio8\
BIO1 = Annual Mean Temperature

BIO4 = Temperature Seasonality (standard deviation ×100)

BIO6 = Min Temperature of Coldest Month\
BIO7 = Temperature Annual Range (BIO5-BIO6)

BIO8 = Mean Temperature of Wettest Quarter

top 90% gives bio4 and bio8\
\
\
\
\

```{r}
collect_metrics(final_fit)
```

### Spatial Predictions

```{r}
chelsa <- terra::rast(chelsa_files) %>%
  terra::crop(bbox, datatype = 'FLT4S') %>%
  setNames(chelsa_names)

pred_rufip <- predict(chelsa, extract_fit_parsnip(final_fit), 
                type = 'prob', cores = available_cores / 2) 

saveRDS(pred, here('data/data-derived/pred_rufip.rds'))

pred_coarse <- terra::aggregate(pred, fact = 10, cores = available.cores)

ggplot() +
  geom_stars(data = st_as_stars(pred_coarse[[1]])) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c() +
  theme_void()

ggplot() +
  geom_stars(data = st_as_stars(pred_coarse[[2]])) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c(option = 'magma') +
  theme_void()

```

No plot the data locations and whether they were guessed correctly . . .

### Partial Dependence Plots

```{r}
library(pdp)

final_fit %>%
  extract_fit_engine() %>%
partial(pred.var = "bio1", train = train, 
        plot.engine = 'ggplot2', prob = TRUE, progress = TRUE) %>%
              plotPartial(lwd = 2, rug = TRUE)
```

```{r}
final_fit %>%
  extract_fit_engine() %>%
partial(pred.var = "bio6", train = train, 
        plot.engine = 'ggplot2', prob = TRUE, progress = TRUE, rug = TRUE) %>%
              plotPartial(lwd = 2)
```

```{r}
final_fit %>%
  extract_fit_engine() %>%
partial(pred.var = "bio11", train = train, 
        plot.engine = 'ggplot2', prob = TRUE, progress = TRUE, rug = TRUE) %>%
              plotPartial(lwd = 2)
```

```{r}
library(DALEXtra)

new <- prep(rec) %>% juice
explainer <- explain_tidymodels(
  extract_fit_parsnip(final_fit),
  new[,-c(1:2)],
  as.numeric(new$rufip) -1,
  type = 'classification'
)

pdp_bio1 <- model_profile(
  explainer,
  variables = "bio1",
  N = 1000
)

plot(pdp_bio1)

ggplot_pdp <- function(obj, x) {
  
  p <- 
    as_tibble(obj$agr_profiles) %>%
    mutate(`_label_` = stringr::str_remove(`_label_`, "^[^_]*_")) %>%
    ggplot(aes(`_x_`, `_yhat_`)) +
    geom_line(data = as_tibble(obj$cp_profiles),
              aes(x = {{ x }}, group = `_ids_`),
              size = 0.5, alpha = 0.05, color = "gray50")
  
  num_colors <- n_distinct(obj$agr_profiles$`_label_`)
  
  if (num_colors > 1) {
    p <- p + geom_line(aes(color = `_label_`), size = 1.2, alpha = 0.8)
  } else {
    p <- p + geom_line(color = "midnightblue", size = 1.2, alpha = 0.8)
  }
  
  p
}

pdp_bio6 <- model_profile(
  explainer,
  variables = "bio6",
  N = 1000
)
ggplot_pdp(pdp_bio6, bio6)  +
  labs(x = "Year built", 
       y = "Sale Price (log)", 
       color = NULL)
```

## planning

so this is all great, but what's next? thinking still about sampling issues . . . do I sample background cells where I have presence points? do I thin the presence points or should I use the raw densities? should I still some kind of downsampling of the background? should I use the 1km extracted predictors instead of the grid cell level predictors? some kind of spatial cross validation scheme?

no that I think about it the idea of going back to raw points is attractive

Pros:

1.  faster prepoccsing
2.  control size of background
3.  faster climate extraction
4.  easier to do spatial cv?
5.  can account for lat with weighted sampling
6.  more information from multiple presence points
7.  more informaiton but likely less data overall

Cons:

1.  unrelaistic preciion in location
2.  more prone to sampling bias?
3.  lower number of background points might make it not represnt the environment as much
4.  cleaner interpretaiton of grid cell classification

I should go back to the SDM how to paper by elith and check some of these off

now as a test, I'll see about the reduced models

```{r}
# pca
base_rec <- train %>%
  recipe() %>%
  update_role(starts_with('bio'), new_role = 'predictor') %>%
  update_role(rufip, new_role = 'outcome') %>%
  update_role(ANL12_ID, new_role = 'id') %>%
  step_bin2factor(all_outcomes()) %>%
  step_rm(!has_role(c('predictor', 'outcome', 'id')))

rec1 <-  base_rec %>%
  step_normalize(all_numeric_predictors()) %>%
  step_pca(num_comp = 5)
 
# bart
rec2 <- train %>%
  recipe(rufip ~ bio1 + bio12 + bio15 + bio2 + bio3) %>%
  step_bin2factor(all_outcomes())

# vip
rec3 <- train %>%
  recipe(rufip ~ bio11 + bio15 + bio4 + bio6 + bio7) %>%
  step_bin2factor(all_outcomes())

# reasonable
rec4 <- train %>%
  recipe(rufip ~ bio1 + bio12 + bio5 + bio6) %>%
  step_bin2factor(all_outcomes())

# mrmr
rec5 <- train %>%
  recipe(rufip ~ bio11 + bio15 + bio18 + bio19 + bio8) %>%
  step_bin2factor(all_outcomes())
  #base_rec %>%
  #step_select_mrmr(all_predictors(), outcome = 'rufip', top_p = 5)

# infogain
rec6 <- train %>%
  recipe(rufip ~ bio1 + bio4 + bio6 + bio7 + bio8) %>%
  step_bin2factor(all_outcomes())
# base_rec %>%
#  step_select_infgain(
#    all_predictors(),
#    outcome = "rufip",
#    nthreads = 0,
#    top_p = 5
#  )

params <- rf_mod %>%
  extract_parameter_set_dials() %>%
  update(mtry = mtry(c(1, 6)))
new_rec <- list(base = base_rec, pca = rec1, bart = rec2, vip = rec3, expert = rec4, mrmr = rec5, info = rec6)
set <- workflow_set(new_rec, list(mod = rf_mod))

registerDoMC(cores = available_cores)
tuning_rec <- workflow_map(set, 'tune_bayes', resamples = folds, metrics = c_metrics, param_info = params)
registerDoSEQ()
```

1,2,6,4,3,5

Interesting, so the PCA performs best, then the BART selected variables, then the top 7 varimp, then varimp top 5, Last two are just bio1 and 12, worse by faris bio11 and 6 which are the top 2 varimp selected ones

So this shows that:

1.  the autoatic varimp fails in the way we'd expect given the colinear predictors
2.  pca does good as always,
3.  so does embarcardero

So why not just use PCA then? It'd be nice to have more direct raw variables ot make it easier to look at th epotential niches curther back in time. Projecting the pca into th past and future is risky, and would require an area of applicability test on the climate data (because what if the correlations change?)

But remeber, this is all with a given level of mtry!

Now retuining with varying mtry and min nodes. This says base and PCA best about equally good. Bart a bit beyond that. notably higher variance in the pr_auc metric. Thats the first tier. In the next tier is expert first and then the three filters. MRMR is the best and VIP is generally notably worse. Overall

```{r}
autoplot(tuning_rec,select_best = TRUE)
```

```{r}
rank_results(tuning_rec, select_best = TRUE) %>%
  select(wflow_id, .metric, mean) %>%
  pivot_wider(names_from = .metric, values_from = mean)
```

So MTRY sometimes tries to go for the really low ranges.

```{r}
map(tuning_rec$result, autoplot)
```

this makes me want to look at the effect of varying mtry

```{r}
small_fit <- final_mod <- rand_forest(mode = 'classification',
                         trees = 1000,
                         mtry = 3,
                         min_n = 5) %>%
  set_engine('ranger',
             importance = 'permutation',
             replace = FALSE,
             sample.fraction = c(0.632 * occ_ratio, 
                                 0.632 * occ_ratio)) %>%
  workflow(base_rec, .) %>%
  fit(train)

small_fit
```

6,15,11,17,18,4,

```{r}
extract_fit_engine(small_fit) %>%
  vip(geom = "point", num_features = 19)
```

```{r}
(as.numeric(new$rufip) %>% unique) * -1 + 2
sdm_step <- embarcadero::bart.step(x.data = new[,-c(1:2)], 
                      y.data = as.numeric(new$rufip) * -1 + 2)
```

## BART

```{r}
#bart_mod <- parsnip::bart(mode = 'classification'#,
                         # trees = tune(),
                        #  prior_terminal_node_coef = tune(),
                         # prior_terminal_node_expo = tune(),
                        #  prior_outcome_range = tune()
 #                         )

#wflw <- workflow(rec, bart_mod)
```

```{r}
registerDoMC(cores = available_cores)

ctrl <- control_bayes(verbose = TRUE, seed = 8154)

tuning <- tune_bayes(bart_mod, rec, folds, initial = 20, control = ctrl, metrics = c_metrics)

registerDoSEQ()
```

```{r}
autoplot(tuning)
```

```{r}
select_best(tuning)
```

```{r}
best_bart <- select_best(tuning) #'mn_log_loss'

saveRDS(best_bart, here('data/data-derived/best_bart.rds'))

best_bart
```

```{r}
final_mod <- finalize_workflow(wflw, best_bart) %>% 
    last_fit(splits, metrics = c_metrics)
collect_metrics(final_mod)
```

```{r}
rf_fit <- rand_forest(mode = 'classification') %>%
  workflow(rec, .) %>%
  last_fit(splits, metrics = c_metrics) 

collect_metrics(rf_fit)
```

```{r}
final_mod %>%
  extract_fit_engine() %>%
  embarcadero::partial(x.vars = c('PC1', 'PC2', 'PC3', 'PC4', 'PC5'),
                       smooth = 3)
```

```{r}
prep(rec) %>%
  tidy(4, matrix = 'u') %>%
  group_by(component) %>%
  arrange(-abs(value), .by_group = TRUE)
```

```{r}
sdm <- fit_resamples(wflw, folds)
```

```{r}
bbox <- st_bbox(c(xmin = 60, xmax =150, ymin= -20, ymax = 50), crs = 4326)

chelsa_files <- list.files('../../CHELSA_V2_bio_clim', full.names = TRUE)[c(2:20)]#, 60:70)]#70)]
chelsa_names <- chelsa_files %>% str_split('_') %>% map_chr(~.x[5])

chelsa <- chelsa_files %>%
  read_stars(shorten = FALSE) %>%
  st_crop(bbox) %>%
  setNames(chelsa_names)

#r <- terra::rast(chelsa)

#a <- terra::aggregate(r, factor = 10)

#s <- st_as_stars(a)
plot(chelsa)
```

## Ecological niche modeling

Sample background points from the CHELSA data for the ENM.

```{r cache = TRUE}
# quick and dirty way to mask the chelsa data for generating background points
mask1 <- read_stars('../campanula/CHELSA_pet_penman_01_1981-2010_V.2.1.tif') %>%
  st_crop(bbox) %>% # crop mask to bbox?
  st_as_stars()
mask <- mask1 / mask1 ; rm(mask1)

set.seed(1536)
sdm_pts <- mask %>% 
  as('Raster') %>% 
  dismo::randomPoints(nrow(progenitor), st_coordinates(progenitor)) %>%
  as_tibble() %>%
  st_as_sf(coords = c(1,2), crs = 4326) %>%
  mutate(rice = 'background') %>%
  bind_rows(progenitor, .)

sdm_pts2 <- mask %>% 
  as('Raster') %>% 
  dismo::randomPoints(nrow(domestic), st_coordinates(domestic)) %>%
  as_tibble() %>%
  st_as_sf(coords = c(1,2), crs = 4326) %>%
  mutate(rice = 'background') %>%
  bind_rows(domestic, .)

sdm_pts3 <- mask %>% 
  as('Raster') %>% 
  dismo::randomPoints(nrow(arch), st_coordinates(arch)) %>%
  as_tibble() %>%
  st_as_sf(coords = c(1,2), crs = 4326) %>%
  mutate(rice = 'background') %>%
  bind_rows(mutate(arch, rice = 'present'), .)

sdm_pts4 <- mask %>% 
  as('Raster') %>% 
  dismo::randomPoints(nrow(oryza), st_coordinates(oryza)) %>%
  as_tibble() %>%
  st_as_sf(coords = c(1,2), crs = 4326) %>%
  mutate(rice = 'background') %>%
  bind_rows(mutate(oryza, rice = 'present'), .)

ggplot(sdm_pts) +
  geom_sf(data = coasts) +
  geom_sf(aes(color = rice), size = 1, alpha = 0.5) +
  theme_minimal()

ggplot(sdm_pts2) +
  geom_sf(data = coasts) +
  geom_sf(aes(color = rice), size = 1, alpha = 0.5) +
  theme_minimal()

ggplot(sdm_pts3) +
  geom_sf(data = coasts) +
  geom_sf(aes(color = rice), size = 1, alpha = 0.5) +
  theme_minimal()
```

Extract the climate data at the presence and background points and fit a random forest model.

```{r}
dat <- st_extract(chelsa, sdm_pts) %>% 
  bind_cols(sdm_pts) %>%
  dplyr::select(-contains('geometry')) %>%
  mutate(rice = as.factor(rice))

mod <- rand_forest(mode = 'classification') %>%
  set_engine('ranger', importance = 'permutation') %>%
  fit(rice ~ ., data = dat)

mod

dat2 <- st_extract(chelsa, sdm_pts2) %>% 
  bind_cols(sdm_pts2) %>%
  dplyr::select(-contains('geometry'), -continent) %>%
  mutate(rice = as.factor(rice))

mod2 <- rand_forest(mode = 'classification') %>%
  set_engine('ranger', importance = 'permutation') %>%
  fit(rice ~ ., data = dat2)

mod2

dat3 <- st_extract(chelsa, sdm_pts3) %>% 
  bind_cols(sdm_pts3) %>%
  dplyr::select(-contains('geometry'), -c(Country, Site, age)) %>%
  mutate(rice = as.factor(rice))

mod3 <- rand_forest(mode = 'classification') %>%
  set_engine('ranger', importance = 'permutation') %>%
  fit(rice ~ ., data = dat3)

mod3
```

Check the variable importances.

```{r}
vip(mod, geom = "point", num_features = 15)
vip(mod2, geom = "point", num_features = 15)
vip(mod3, geom = "point", num_features = 15)
```

Map the predicted niche of each dataset.

```{r}
pred <- chelsa %>%
  st_crop(bbox) %>%
  predict(mod, type = 'prob') 

pred2 <- chelsa %>%
  st_crop(bbox) %>%
  predict(mod2, type = 'prob') 

pred3 <- chelsa %>%
  st_crop(bbox) %>%
  predict(mod3, type = 'prob') 

ggplot() +
  geom_stars(data = pred['.pred_present'], downsample = 20) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c() +
  theme_void()

ggplot() +
  geom_stars(data = pred2['.pred_present'], downsample = 20) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c() +
  theme_void()

ggplot() +
  geom_stars(data = pred3['.pred_present'], downsample = 20) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c() +
  theme_void()
```

```{r}
ggplot() +
  geom_stars(data = pred['.pred_present'], downsample = 10) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c() +
  theme_void()

ggplot() +
  geom_stars(data = st_as_stars(pred_coarse[[1]])) +
  geom_sf(data = coasts, color = 'white') +
  scale_fill_viridis_c() +
  theme_void()
```

## Model selection with BART

Use Bayesian additive regression trees for more interpretable niche modeling.

```{r}
# install.packages('remotes')
#remotes::install_github('cjcarlson/embarcadero')
#install.packages('reshape')
library(embarcadero)

xvars <- names(dat)[!(names(dat) == 'rice')]
## Run the BART model
sdm <- bart(y.train = as.numeric(dat$rice)-1,
 x.train=dat[,xvars], 
 keeptrees = TRUE)

summary(sdm)

## Visualize model performance

```

```{r}
## Predict the species distribution
map <- predict(sdm, as(merge(chelsa), 'RasterStack'))
```

```{r cache = TRUE}
sdm_step <- bart.step(x.data = dat[,xvars], 
                      y.data = as.numeric(dat$rice) - 1,
                      full = TRUE)
```

BIO1 = Annual Mean Temperature

BIO12 = Annual Precipitation

BIO15 = Precipitation Seasonality (Coefficient of Variation)

BIO2 = Mean Diurnal Range (Mean of monthly (max temp - min temp))

BIO3 = Isothermality (BIO2/BIO7) (×100)

```{r fig.width = 10, fig.height=10}
sdm_simp <- bart(y.train = as.numeric(dat$rufip)-1, # or rice!
 x.train=dat[,c('bio1',  'bio12', 'bio15', 'bio2', 'bio3')], 
 keeptrees = TRUE)

partial(sdm_simp, 
        x.vars = c('bio1',  'bio12', 'bio15', 'bio2', 'bio3'),
    ci = TRUE,
    panel = TRUE,
    smooth = 3)
```

```{r}
p <- pd2bart(sdm_simp, xind = c('bio1', 'bio12'), pl = TRUE)
```

```{r}
ggplot() +
  geom_stars(data = chelsa['bio1'] >= 20, downsample = 20) +
  geom_sf(data = coasts, color = 'white')
ggplot() +
  geom_stars(data = chelsa['bio12'] >= 1000, downsample = 20) +
  geom_sf(data = coasts, color = 'white')

chelsa %>%
  st_crop(bbox) %>%
  transmute(test = bio10 > 26) %>%
  plot()
```

```{r}
covs <- chelsa %>%
  st_crop(bbox) %>%
  .[c(1,4, 7,12,13),,] %>%
  merge() %>%
  as('Raster')

ggplot() +
  geom_stars(data = st_as_stars(covs)[,,,1], downsample = 30) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')

ggplot() +
  geom_stars(data = st_as_stars(covs)[,,,2], downsample = 30) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')

ggplot() +
  geom_stars(data = st_as_stars(covs)[,,,3], downsample = 30) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')

ggplot() +
  geom_stars(data = st_as_stars(covs)[,,,4], downsample = 30) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')

ggplot() +
  geom_stars(data = st_as_stars(covs)[,,,5], downsample = 30) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')

```

```{r}
sp.bio <- spartial(sdm_step, covs, x.vars = c('bio1', 'bio12', 'bio15', 'bio2', 'bio3'), equal = TRUE) %>%
  st_as_stars()

ggplot() +
  geom_stars(data = sp.bio, downsample = c(20,20,0)) +
  geom_sf(data = coasts, color = 'white') +
  facet_wrap(~band) +
  scale_fill_viridis_c(option = 'magma') +
  theme_void()
```

## CHELSA-TRACE

```{r}
bio_trace <- '../../Data/CHELSA/chelsa_trace/bio01/' %>%
  list.files(full.names = TRUE) %>%
  .[c(36, 14, 114)] %>%
  read_stars() %>%
  st_crop(bbox) 

plot(bio_trace >= 20)
plot(bio_trace[2] >= 20)
plot(bio_trace[3] >= 20)
plot(chelsa[1] >= 20)
```

```{r}
bio_trace2 <- '../../Data/CHELSA/chelsa_trace/bio12/' %>%
  list.files(full.names = TRUE) %>%
  .[c(36, 14, 114)] %>%
  read_stars() %>%
  st_crop(bbox) 

plot(bio_trace2 >= 1000)
plot(bio_trace2[2] >= 1000)
plot(bio_trace2[3] >= 1000)
plot(chelsa[4] >= 1000)

ggplot() +
  geom_stars(data = bio_trace2[3] - bio_trace2[1], downsample = 20) +
  scale_fill_distiller(palette = 'RdBu', limits = c(-1100, 1100))
```

## Global Rice Data

```{r}
rice_map <- list(here('data', 'monfreda', 'rice_YieldPerHectare.tif'),
     here('data', 'monfreda', 'rice_HarvestedAreaHectares.tif')) %>%
  read_stars() %>%
  st_crop(bbox)

ggplot() +
  geom_stars(data = rice_map) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')

ggplot() +
  geom_stars(data = rice_map[2]) +
  scale_fill_viridis_c(trans = 'log') +
  geom_sf(data = coasts, color = 'white')
```

```{r}
rice_map2 <- crop_spam('rice', var = 'area') %>%
  st_as_stars() %>%
  st_crop(bbox)

ggplot() +
  geom_stars(data = rice_map2[,,,2]) +
  scale_fill_viridis_c() +
  geom_sf(data = coasts, color = 'white')
```

```{r}
library(mgcv)
library(stars)

age_gam <- bind_cols(rice, st_coordinates(rice)) %>%
  rename(x =X, y = Y) %>%
  select(age, x, y) %>%
  filter(age > -1200) %>%
  gam(age ~ s(x, y), data = .)

as_tibble(ref) %>%
  mutate( pred = predict(age_gam, as_tibble(ref), type = 'response')) 

  ggplot() +
  geom_stars(data = age) +
    geom_sf(data = coasts) +
    scale_fill_viridis_c(direction = -1)
  
  

```

## 

## Archaeological Data

```{r}
library(mgcv)
rec %>% prep %>% juice %>%
  gam(arch ~ s(bio1) + s(bio12) + s(bio15) + s(bio2) + s(bio3), data = ., family = binomial()) %>%
  plot(trans = plogis)
```

Look at the distribution of ages of archaeological rice remains.

```{r}
rice %>%
  ggplot(aes(age)) +
  geom_histogram() +
  scale_x_continuous(breaks = seq(-14000, 1000, 2000))
```

And changing distributions over time.

```{r, fig.width= 8, fig.height = 6}
rice %>%
  mutate(millennium = floor(age/1000)) %>%
ggplot() +
  geom_sf() +
  scale_color_viridis_c() +
  facet_wrap(~millennium) +
   geom_sf(data = coasts) +
  theme_bw()
```

## 

TODO

-   5min CHELSA data

-   Oryza genus model

-   world vs asia comparison

-   xgboost
